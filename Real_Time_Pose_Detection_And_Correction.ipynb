{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully library installed\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import cv2 \n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Successfully library installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming mp_drawing and mp_pose have already been defined as:\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "def detectPose(image, pose, display=True):\n",
    "    # Create a copy of the image\n",
    "    output_image = image.copy()\n",
    "    # Convert the image to RGB\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the image with pose detection\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # Get the height and width of the image\n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "\n",
    "    # If pose landmarks are found\n",
    "    if results.pose_landmarks:\n",
    "        # Draw the pose landmarks on the output image\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks, connections=mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        # Append the landmarks' coordinates to the list\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append(\n",
    "                (int(landmark.x * width), int(landmark.y * height), landmark.z * width)\n",
    "            )\n",
    "    \n",
    "    if display:\n",
    "        # Display the original input image and the resultant image\n",
    "        plt.figure(figsize=[22, 22])\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        plt.imshow(image[:, :, ::-1])  # Convert BGR to RGB\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        plt.imshow(output_image[:, :, ::-1])  # Convert BGR to RGB\n",
    "        plt.title(\"Output Image\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Also plot the Pose landmarks in 3D\n",
    "        if results.pose_world_landmarks:\n",
    "            mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "    else:\n",
    "        # Return the output image and the found landmarks\n",
    "        return output_image, landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Setup Pose function for video\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam or video file\n",
    "video = cv2.VideoCapture(0)  # Change the index to the video file path if needed\n",
    "\n",
    "# Create named window for resizing purposes\n",
    "cv2.namedWindow('Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Initialize video size (optional)\n",
    "video.set(3, 1280)  # Width\n",
    "video.set(4, 960)   # Height\n",
    "\n",
    "# Initialize a variable to store the time of the previous frame\n",
    "time1 = 0\n",
    "\n",
    "while video.isOpened():\n",
    "    # Read a frame\n",
    "    ok, frame = video.read()\n",
    "\n",
    "    if not ok:\n",
    "        break  # Break the loop if the frame is not read properly\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Perform Pose landmark detection\n",
    "    imageRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose_video.process(imageRGB)\n",
    "\n",
    "    # Calculate FPS\n",
    "    time2 = time.time()\n",
    "    if time2 - time1 > 0:\n",
    "        frames_per_second = 1.0 / (time2 - time1)\n",
    "    else:\n",
    "        frames_per_second = 0\n",
    "    time1 = time2\n",
    "\n",
    "    # Display FPS on the frame\n",
    "    cv2.putText(frame, f'FPS: {int(frames_per_second)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)\n",
    "\n",
    "    # Draw landmarks and connections if pose landmarks are detected\n",
    "    if results.pose_landmarks:\n",
    "        mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    # Wait until a key is pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Check if 'ESC' key is pressed to break the loop\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close the windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_angle(landmark1, landmark2, landmark3):\n",
    "    \"\"\"\n",
    "    This function calculates the angle between three different landmarks.\n",
    "\n",
    "    Args:\n",
    "    landmark1: The first landmark containing the x, y, and z coordinates.\n",
    "    landmark2: The second landmark containing the x, y, and z coordinates.\n",
    "    landmark3: The third landmark containing the x, y, and z coordinates.\n",
    "\n",
    "    Returns:\n",
    "    angle: The calculated angle between the three landmarks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the required landmark coordinates\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "\n",
    "    # Ensure the angle is between 0 and 360 degrees\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pose(landmarks, output_image, display=False):\n",
    "    \"\"\"\n",
    "    This function classifies yoga poses depending upon the angles of various body joints.\n",
    "    \n",
    "    Args:\n",
    "    landmarks: A list of detected landmarks of the person whose pose needs to be classified.\n",
    "    output_image: An image of the person with the detected pose landmarks drawn.\n",
    "    display: A boolean value; if set to True, the function displays the resultant image.\n",
    "    \n",
    "    Returns:\n",
    "    output_image: The image with the detected pose landmarks and pose label.\n",
    "    label: The classified pose label.\n",
    "    \"\"\"\n",
    "    # Initialize the label as 'Unknown Pose'\n",
    "    label = 'Unknown Pose'\n",
    "\n",
    "    # Specify color (Red) with which the label will be written\n",
    "    color = (0, 0, 255)  # Red color\n",
    "\n",
    "    # Calculate the required angles (shoulders, elbows, knees)\n",
    "    left_elbow_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    right_elbow_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                        landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                        landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    \n",
    "    left_shoulder_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "    \n",
    "    right_shoulder_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                           landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                           landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "    \n",
    "    # Knee angles (for leg checking)\n",
    "    left_knee_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    \n",
    "    right_knee_angle = calculate_angle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "    # Warrior II Pose Classification\n",
    "    if 165 < left_elbow_angle < 195 and 165 < right_elbow_angle < 195:\n",
    "        if 80 < left_shoulder_angle < 110 and 80 < right_shoulder_angle < 110:\n",
    "            if 90 < left_knee_angle < 120 and 90 < right_knee_angle < 120:\n",
    "                label = 'Warrior II Pose'\n",
    "\n",
    "    # Check if both legs are straight for T Pose\n",
    "    if 160 < left_knee_angle < 195 and 160 < right_knee_angle < 195:\n",
    "        label = 'T Pose'\n",
    "\n",
    "    # Check if it is the Tree pose\n",
    "    if (165 < left_knee_angle < 195 or 165 < right_knee_angle < 195):\n",
    "        if (315 < left_knee_angle < 335 or 25 < right_knee_angle < 45):\n",
    "            label = 'Tree Pose'\n",
    "\n",
    "    # Check if the pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        # Update the color (to green) with which the label will be written on the image\n",
    "        color = (0, 255, 0)\n",
    "        \n",
    "    # Write the label on the output image\n",
    "    cv2.putText(output_image, label, (10, 30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "\n",
    "    # Check if the resultant image is specified to be displayed\n",
    "    if display:\n",
    "        # Display the resultant image\n",
    "        plt.figure(figsize=[10, 10])\n",
    "        plt.imshow(output_image[:, :, ::-1])\n",
    "        plt.title(\"Output Image\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    # Return the output image and label regardless of display\n",
    "    return output_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initialize the videoCapture object to read from the webcam\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3, 1280)\n",
    "camera_video.set(4, 960)\n",
    "\n",
    "# Initialize a resizable window.\n",
    "cv2.namedWindow('Pose Classification', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Iterate until the webcam is accessed successfully\n",
    "while camera_video.isOpened():\n",
    "\n",
    "    # Read a frame\n",
    "    ok, frame = camera_video.read()\n",
    "\n",
    "    # Check if frame is not read properly\n",
    "    if not ok:\n",
    "        # Continue to the next iteration to read the next frame and ignore the empty camera frame\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Get the width and height of the frame\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    # Resize the frame while keeping the aspect ratio\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "    \n",
    "    # Detect Pose landmarks\n",
    "    result,landmarks = detectPose(frame, pose_video, display=False)\n",
    "    \n",
    "        # Check if the Landmarks are detected\n",
    "    if landmarks:\n",
    "        frame, _ = classify_pose(landmarks, frame, display=False)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "    # Wait until a key is pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Check if 'ESC' is pressed.\n",
    "    if k == 27:\n",
    "        # Break the Loop\n",
    "        break\n",
    "\n",
    "# Release the Videocapture object and close the windows\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
